{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Classes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image dimensions:\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/image-processing/train'\n",
    "validation_data_dir = 'data/image-processing/test'\n",
    "\n",
    "#Clissification\n",
    "nb_train_samples = 1000\n",
    "nb_validation_samples = 500 #800\n",
    "epochs = 50 #loop counter to send batch for analysis \n",
    "batch_size = 20 #16 #1 batch will have 20 images\n",
    "\n",
    "if backend.image_data_format() == 'channels_first': \n",
    "    #RGB first then width and height\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    #150,150,3 # Width at first then height and RGB\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "#Generate Training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#this is the augmentation configuration we will use for testing: only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuralnetwork Creation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 74, 74, 32)        0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=input_shape))\n",
    "#Conv2D: Convinutional network used to extract feature from the image. Here 32 distinct features will be extracted within 3X3 pixels\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.summary()\n",
    "print('-------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "print('-------------------------------------------------------------------------------------------------------------------')\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu')) # relu: returns either 0 or 1\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "print('-------------------------------------------------------------------------------------------------------------------')\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data for Above Nural Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 32s 642ms/step - loss: 0.4198 - accuracy: 0.8090 - val_loss: 0.6482 - val_accuracy: 0.6920\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 47s 953ms/step - loss: 0.3557 - accuracy: 0.8650 - val_loss: 0.4757 - val_accuracy: 0.7900\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 47s 932ms/step - loss: 0.3123 - accuracy: 0.8650 - val_loss: 0.8613 - val_accuracy: 0.7280\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 0.2789 - accuracy: 0.9010 - val_loss: 0.7089 - val_accuracy: 0.7640\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 0.3073 - accuracy: 0.8800 - val_loss: 0.3699 - val_accuracy: 0.8240\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 40s 799ms/step - loss: 0.2719 - accuracy: 0.8916 - val_loss: 0.5985 - val_accuracy: 0.8120\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 0.2912 - accuracy: 0.8880 - val_loss: 0.3647 - val_accuracy: 0.8480\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 0.2874 - accuracy: 0.8960 - val_loss: 0.4421 - val_accuracy: 0.8240\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 36s 723ms/step - loss: 0.2268 - accuracy: 0.9036 - val_loss: 0.5952 - val_accuracy: 0.8060\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 0.2161 - accuracy: 0.9130 - val_loss: 0.5649 - val_accuracy: 0.7960\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 38s 752ms/step - loss: 0.2332 - accuracy: 0.9170 - val_loss: 0.3145 - val_accuracy: 0.8760\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.2500 - accuracy: 0.9040 - val_loss: 0.4426 - val_accuracy: 0.8200\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 46s 930ms/step - loss: 0.2282 - accuracy: 0.9096 - val_loss: 0.5374 - val_accuracy: 0.7980\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 47s 938ms/step - loss: 0.2005 - accuracy: 0.9230 - val_loss: 0.7367 - val_accuracy: 0.7700\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 48s 965ms/step - loss: 0.2068 - accuracy: 0.9230 - val_loss: 0.5477 - val_accuracy: 0.8520\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 46s 912ms/step - loss: 0.2267 - accuracy: 0.9130 - val_loss: 0.5514 - val_accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.1949 - accuracy: 0.9260 - val_loss: 0.4691 - val_accuracy: 0.8820\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 47s 954ms/step - loss: 0.2087 - accuracy: 0.9300 - val_loss: 0.3771 - val_accuracy: 0.8940\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 47s 950ms/step - loss: 0.1856 - accuracy: 0.9357 - val_loss: 0.5668 - val_accuracy: 0.8440\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 56s 1s/step - loss: 0.1969 - accuracy: 0.9357 - val_loss: 0.6884 - val_accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 48s 956ms/step - loss: 0.1910 - accuracy: 0.9340 - val_loss: 0.6836 - val_accuracy: 0.7780\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 39s 778ms/step - loss: 0.1985 - accuracy: 0.9270 - val_loss: 0.5528 - val_accuracy: 0.8140\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 0.1773 - accuracy: 0.9347 - val_loss: 0.3373 - val_accuracy: 0.8900\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 39s 779ms/step - loss: 0.2392 - accuracy: 0.9380 - val_loss: 0.5015 - val_accuracy: 0.8220\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 40s 795ms/step - loss: 0.2017 - accuracy: 0.9367 - val_loss: 0.4556 - val_accuracy: 0.8520\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 41s 825ms/step - loss: 0.1854 - accuracy: 0.9350 - val_loss: 0.3243 - val_accuracy: 0.8960\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 0.2057 - accuracy: 0.9327 - val_loss: 0.2863 - val_accuracy: 0.8920\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 44s 881ms/step - loss: 0.1888 - accuracy: 0.9300 - val_loss: 0.4287 - val_accuracy: 0.8440\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 40s 805ms/step - loss: 0.1819 - accuracy: 0.9327 - val_loss: 0.4693 - val_accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.2014 - accuracy: 0.9310 - val_loss: 0.3508 - val_accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.1829 - accuracy: 0.9357 - val_loss: 0.3761 - val_accuracy: 0.9020\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 47s 945ms/step - loss: 0.1954 - accuracy: 0.9280 - val_loss: 0.4045 - val_accuracy: 0.8920\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 0.1549 - accuracy: 0.9498 - val_loss: 0.5678 - val_accuracy: 0.8500\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 52s 1s/step - loss: 0.2002 - accuracy: 0.9317 - val_loss: 0.4275 - val_accuracy: 0.8400\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 46s 917ms/step - loss: 0.1967 - accuracy: 0.9237 - val_loss: 0.3985 - val_accuracy: 0.8840\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 47s 947ms/step - loss: 0.1845 - accuracy: 0.9330 - val_loss: 0.5169 - val_accuracy: 0.8760\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 49s 989ms/step - loss: 0.1786 - accuracy: 0.9430 - val_loss: 0.4137 - val_accuracy: 0.8660\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.2327 - accuracy: 0.9297 - val_loss: 0.2649 - val_accuracy: 0.9160\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 47s 945ms/step - loss: 0.2093 - accuracy: 0.9410 - val_loss: 0.5841 - val_accuracy: 0.8340\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 49s 985ms/step - loss: 0.1875 - accuracy: 0.9310 - val_loss: 0.3500 - val_accuracy: 0.8620\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.1890 - accuracy: 0.9337 - val_loss: 0.3075 - val_accuracy: 0.8800\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.1817 - accuracy: 0.9370 - val_loss: 0.2734 - val_accuracy: 0.9100\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.1695 - accuracy: 0.9388 - val_loss: 0.6454 - val_accuracy: 0.7920\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 50s 1000ms/step - loss: 0.1829 - accuracy: 0.9360 - val_loss: 0.5337 - val_accuracy: 0.8680\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 41s 828ms/step - loss: 0.1871 - accuracy: 0.9430 - val_loss: 0.4410 - val_accuracy: 0.8780\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 33s 652ms/step - loss: 0.1745 - accuracy: 0.9420 - val_loss: 0.8917 - val_accuracy: 0.8080\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 33s 670ms/step - loss: 0.2014 - accuracy: 0.9370 - val_loss: 0.7037 - val_accuracy: 0.8100\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 35s 704ms/step - loss: 0.1667 - accuracy: 0.9490 - val_loss: 0.4863 - val_accuracy: 0.8920\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 33s 656ms/step - loss: 0.1863 - accuracy: 0.9420 - val_loss: 0.4084 - val_accuracy: 0.8740\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 32s 649ms/step - loss: 0.1580 - accuracy: 0.9450 - val_loss: 0.4668 - val_accuracy: 0.8280\n",
      "[[1.]]\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples//batch_size)\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDECTION ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "img_pred = image.load_img('data/image-processing/val/NORMAL/NORMAL2-IM-1431-0001.jpeg', target_size=(150,150))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred, axis = 0)\n",
    "\n",
    "rslt = model.predict(img_pred)\n",
    "print(rslt)\n",
    "if rslt[0][0] == 1:\n",
    "    prediction = \"Normal\"\n",
    "else:\n",
    "    prediction = 'Infected'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
